<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>設計ノート on 天才まくまくノート</title><link>https://maku77.github.io/memo/</link><description>Recent content in 設計ノート on 天才まくまくノート</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Sat, 28 Apr 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://maku77.github.io/memo/index.xml" rel="self" type="application/rss+xml"/><item><title>faceswap/ffmpeg で動画の顔を好きな顔に置き換える</title><link>https://maku77.github.io/p/vfsc5ra/</link><pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/vfsc5ra/</guid><description>概要 faceswap というツールを使用すると、機械学習の技術を使用して2人の画像の顔を入れ替えることができます。
このツール自体は静止画を対象としているので、動画の顔を入れ替えることはできないのですが、
ffmpeg を使って動画から静止画を生成 faceswap を使って静止画の顔を入れ替える ffmpeg を使って静止画を結合して動画を生成 というステップを踏むことによって、結果的に動画内の顔を入れ替えるということができます。
faceswap 環境のインストール faceswap のダウンロード まずは、下記サイトの Clone or download ボタンを押して、zip ファイルをダウンロードします（約100MB）。
https://github.com/deepfakes/faceswap faceswap は Python 製のツールであり、tensorflow などパッケージをインストールする必要があります。 Dockerfile が用意されていますので、Docker の実行環境 がインストールされているのであれば、比較的簡単に faceswap の実行環境を整えることができます。 Python 製のツールなので、Virtualenv を使って仮想環境を整えることもできます。
以下、Docker による環境構築方法と、Virtualenv による環境構築方法をそれぞれ示します（本家の INSTALL ドキュメントはこちらの情報が元になっています）。
Docker コンテナで faceswap 環境を作る場合 Docker がインストールされていない (docker コマンドが使えない) 場合は、まずは Docker をインストールします。
Install Docker 例えば Mac であれば、下記から docker.dmg をダウンロードして簡単にインストールできます。
Docker Community Edition for Mac Docker 環境のインストールができたら、faceswap に付属している Dockerfile を使用して、Docker コンテナをビルドします（10分程度かかります）。 ここでは、CPU 版のコンテナを作成します。</description></item><item><title>スケジューリングや見積りの段階では要求と設計要素のマトリクスで考える</title><link>https://maku77.github.io/p/b27pn7d/</link><pubDate>Wed, 02 Nov 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/b27pn7d/</guid><description>ソフトウェアで実現したいこと（ここでは「要求」と呼ぶことにします）と、そのために必要な設計要素は多対多の関係になることが多く、開発スケジュールを決める段階では、その関係を把握することポイントになってきます。
例えば、
要求 1 を実現するには、設計要素 A と B の実装が必要 要求 2 を実現するには、設計要素 A と C の実装が必要 といったケースでは、要求 1 と要求 2 の実装工数を別々に見積ることにあまり意味はありません。 なぜなら、それらを実現するために必要な設計要素 A が重複しているため、単純に合計したときに正しい見積りとならないからです（過大な工数見積りになってしまう）。 つまり、工数見積りは、あくまで設計要素に対して行い、それらの組み合わせとしてどの要求が満たされるか、といった考え方をするべきです。
要求変更や仕様変更に対する設計要素への影響を見える化するための「トレーサビリティ・マトリクス」という考え方がありますが、プロジェクトの初期段階ではそこまでしっかりとした表を作る必要はなく、ざっと工数見積りを行うための表を描いてみるとよいです。 例えば以下のような感じです。
工数 要求1 要求2 設計要素 A 7 ● ● 設計要素 B 1 ● 設計要素 C 3 ● このような表があれば、要求 1 だけを実現するための工数は 8 (7+1)、要求 2 だけを実現するための工数は 4 (1+3)、両方を実現するための工数は 11 (7+1+3)、と見積ることができます。 どのような実装をすれば、より少ない工数でより多くの要求を満たすことができるのかを把握できるようになります。</description></item><item><title>Jenkins ジョブの設定 (config.xml) を確認する</title><link>https://maku77.github.io/p/ncmh8bj/</link><pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/ncmh8bj/</guid><description>下記のようなアドレスにアクセスすると、そのジョブの設定情報 config.xml を確認することができます。 この情報は、Jenkins の REST API などを使用してジョブを作成するときに必要になります。
http://localhost:8080/job/＜ジョブ名＞/config.xml config.xml の例 &amp;lt;?xml version=&amp;#39;1.0&amp;#39; encoding=&amp;#39;UTF-8&amp;#39;?&amp;gt; &amp;lt;project&amp;gt; &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt; &amp;lt;keepDependencies&amp;gt;false&amp;lt;/keepDependencies&amp;gt; &amp;lt;properties/&amp;gt; &amp;lt;scm class=&amp;#34;hudson.scm.NullSCM&amp;#34;/&amp;gt; &amp;lt;canRoam&amp;gt;true&amp;lt;/canRoam&amp;gt; &amp;lt;disabled&amp;gt;false&amp;lt;/disabled&amp;gt; &amp;lt;blockBuildWhenDownstreamBuilding&amp;gt;false&amp;lt;/blockBuildWhenDownstreamBuilding&amp;gt; &amp;lt;blockBuildWhenUpstreamBuilding&amp;gt;false&amp;lt;/blockBuildWhenUpstreamBuilding&amp;gt; &amp;lt;triggers/&amp;gt; &amp;lt;concurrentBuild&amp;gt;false&amp;lt;/concurrentBuild&amp;gt; &amp;lt;builders/&amp;gt; &amp;lt;publishers/&amp;gt; &amp;lt;buildWrappers/&amp;gt; &amp;lt;/project&amp;gt;</description></item><item><title>Amazon EC2 に Jenkins をインストールする</title><link>https://maku77.github.io/p/e8gyjh2/</link><pubDate>Fri, 14 Oct 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/e8gyjh2/</guid><description>ここでは、EC2 インスタンスとして、Amazon Linux AMI (t2.micro) を選択した場合の Jenkins インストール方法を示します。
EC2 サーバへ Jenkins をインストールする EC2 インスタンスのコンソール上で下記のようにインストールできます（基本的に CentOS におけるセットアップ方法と同様です）。
システム全体の更新 $ sudo yum -y update OpenJDK 1.8 のインストール $ sudo yum install -y java-1.8.0-openjdk-devel.x86_64 $ sudo alternatives --set java /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/bin/java yum でインストールできる JDK のバージョンは yum search openjdk-devel で確認できます。 alternatives コマンドでの切り替え先の JDK パスは、sudo alternatives --config java で確認できます（そこから数字を指定して選択することもできます）。 OpenJDK 1.8 だけ入っていればよいのであれば、先に yum remove java で OpenJDK 1.7 をアンインストールしちゃうって手もありです。
Jenkins のインストール $ sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.</description></item><item><title>Groovy スクリプトで Jenkins サーバを制御する</title><link>https://maku77.github.io/p/n2rd4bp/</link><pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/n2rd4bp/</guid><description>Jenkins の API Jenkins CLI の groovy コマンドを使用すると、Groovy スクリプトを使って Jenkins サーバの制御を行えるようになります。 下記の Jenkins API を自由に扱うことができるので、ほとんどどのような処理もスクリプトで自動化することができます。
Jenkins Javadoc Jenkins CLI で Groovy スクリプトを実行する まずは、下記の記事を参考にして、Jenkins CLI コマンドを実行できるようにしておく必要があります。
Jenkins CLI を使ってコマンドラインから Jenkins を操作する Jenkins CLI が使用できるようになったら、groovy コマンドで実行したい Groovy スクリプトを指定すれば OK です。
$ java -jar jenkins-cli.jar -s http://localhost:8080 groovy sample.groovy 下記のサンプルスクリプトは、Jenkins のインストールされているディレクトリから再帰的にすべてのファイルを検索し、config.xml というファイルが見つかったときに、その絶対パスを表示しています。
sample.groovy root = jenkins.model.Jenkins.instance.getRootDir() println &amp;#34;Seach files in ${root.getPath()} ...&amp;#34; root.eachFileRecurse { file -&amp;gt; if (file.getName() == &amp;#39;config.xml&amp;#39;) { println file.getPath() } } ちなみに、Groovy の == 演算子は equals() による比較として扱われるので、上記のように文字列比較も == 演算子で行えます。</description></item><item><title>Groovy スクリプトで Jenkins 上のすべての Job を制御する</title><link>https://maku77.github.io/p/xpnasmv/</link><pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/xpnasmv/</guid><description>すべてのジョブを列挙する 下記のサンプルコードは、Jenkins で定義されているすべてのジョブの情報を表示します。 スクリプトコンソールに張り付けて実行することができます。
sample.groovy jenkins.model.Jenkins.instance.items.each { job -&amp;gt; println &amp;#34;Name: ${job.name}&amp;#34; println &amp;#34;Class: ${job.class}&amp;#34; println &amp;#34;Root Dir: ${job.rootDir}&amp;#34; println &amp;#34;URL: ${job.url}&amp;#34; println &amp;#34;Absolute URL: ${job.absoluteUrl}&amp;#34; println &amp;#34;Description: ${job.description}&amp;#34; if (job.lastSuccessfulBuild != null) { println &amp;#34;Last successful time: ${job.lastSuccessfulBuild.timestamp.time}&amp;#34; } println &amp;#39;----&amp;#39; } ループ中に参照可能な Job オブジェクトの詳細に関しては、下記の API ドキュメントを参照してください。
hudson.model.Job クラス 実行結果 Name: MySampleJob1 Class: class hudson.model.FreeStyleProject Root Dir: C:\app\Jenkins\jobs\MySampleJob1 URL: job/MySampleJob1/ Absolute URL: http://localhost:8080/job/MySampleJob1/ Description: despcription text Last successful time: Tue Aug 23 16:34:04 JST 2016 ---- Name: MySampleJob2 Class: class hudson.</description></item><item><title>Groovy スクリプトで Jenkins 上のすべてのスレーブを制御する</title><link>https://maku77.github.io/p/g4f45uo/</link><pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/g4f45uo/</guid><description>下記のサンプルでは、現在マスターサーバに登録されている Jenkins スレーブをループで処理しています。 ループ中は、Slave オブジェクトの情報を扱うことができます。
hudson.model.Slave クラス スレーブの登録情報を列挙する slave-info.groovy for (slave in jenkins.model.Jenkins.instance.slaves) { println &amp;#34;Slave name: ${slave.name}&amp;#34; println &amp;#34;Slave class: ${slave.class}&amp;#34; println &amp;#34;Slave node description: ${slave.nodeDescription}&amp;#34; println &amp;#34;Slave root path: ${slave.rootPath}&amp;#34; println &amp;#34;Slave label: ${slave.labelString}&amp;#34; println &amp;#34;Slave num executors: ${slave.numExecutors}&amp;#34; println &amp;#39;----&amp;#39; } 実行結果 Slave name: mynode1 Slave class: class hudson.slaves.DumbSlave Slave node description: xxx Slave URL: xxx Slave label: xxx Slave num executors: 1 --- ... スレーブとなっている PC がオンラインかどうか確認する slave-check-online.</description></item><item><title>Jenkins CLI を使ってコマンドラインから Jenkins を操作する</title><link>https://maku77.github.io/p/j3ujkhd/</link><pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/j3ujkhd/</guid><description>Jenkins CLI とは Jenkins CLI (Jenkins Command Line Interface) クライアントを使用すると、コマンドラインから Jenkins サーバを操作することができるようになります。 例えば、Job の設定変更や、ビルドのトリガなどをコマンドラインから行うことができます。 また、Groovy のスクリプトを流し込んで Jenkins サーバ上で実行することも行えるため、Jenkins に対して行う作業のほとんどを自動化することができるようになっています。
Jenkins CLI のインストール CLI の実体は、Jenkins サーバからダウンロードできる jenkins-cli.jar です。 このファイルは任意の Jenkins サーバからダウンロードできますが、一応バージョンの問題が発生しないように、操作対象としている Jenkins サーバからダウンロードするのがよいでしょう。
ローカルホストで Jenkins サーバを稼働しているのであれば、下記のアドレスからダウンロードできます。
http://localhost:8080/jnlpJars/jenkins-cli.jar Jenkins CLI を使ってみる Jenkins CLI は、下記のようなフォーマットで使用します。
$ java -jar jenkins-cli.jar -s &amp;lt;Jenkinsサーバアドレス&amp;gt; &amp;lt;コマンド&amp;gt; 下記は、Jenkins CLI を使ってログイン、ヘルプの表示、ログアウトを実行する例です。 Jenkins CLI の各種コマンドを実行するには、最初に login コマンドを使用して、Jenkins ユーザ名を指定してログインしておく必要があります。
$ java -jar jenkins-cli.jar -s http://localhost:8080 login --username yourname Password: （指定した Jenkins ユーザのパスワードを入力） $ java -jar jenkins-cli.</description></item><item><title>ソフトウェアの静的品質と動的品質</title><link>https://maku77.github.io/p/qy4ft3i/</link><pubDate>Fri, 24 Jun 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/qy4ft3i/</guid><description>ソフトウェアの品質を語るときは、動的品質の前に静的品質を重視せよというお話です。
静的品質と動的品質 ソフトウェアの品質には、大きく分けて静的品質と動的品質があると言えます。
静的品質: ソースコードそのものの品質 ソースコードの可読性は高いか？第三者が読んでも理解できるようになっているか？ メンテナンス性の高い設計になっているか？ 不具合の入りにくい設計（入れることが困難なアーキテクチャ）になっているか？ ドキュメンテーションコメントは簡潔かつ明確に記述されているか？ 動的品質: 実行時の品質 要求された機能が正しく動作するか？ 実行時のパフォーマンスはよいか？ユーザビリティは高いか？ ユニットテストはパスしているか？ 一般的に、ソフトウェア品質というと動的品質の方ばかりが注目されがちです。 なぜなら、多くの場合、ソフトウェアベンダの評価やプログラマ自身の評価が、納品したソフトウェアを実際に動作させたときの動的品質に基いて行われることが多いからです（不具合発生件数の少なさなど）。 ソースコード自体のメンテナンス性（静的品質）が低いということで評価が下げられることはあまりないのではないでしょうか？ ひどいケースになると、一度納品したソフトウェアのメンテナンスは、別のチームが引き継ぐことに決まっているからという理由で、将来のメンテナンス性を放棄したコーディングが行われることがあります。 リリースするソフトウェアが正しく動作することを考えてコーディングするのは当然ですが、プロの職業プログラマ（プロプログラマ？）であれば、将来的なメンテナンス性を意識したコーディングを行えなければいけません。
会社の立場から言えば、最終的にビジネスインパクトが大きくなるのは静的品質の方です。 なぜならば、ソースコード自体の保守性が低いと、将来的に設計変更するときに莫大なコスト（人件費）がかかり、不具合が入り込む可能性も上がってくるからです。そして、これは関連プロジェクトが存続する限り、永遠に続くコストとして積みあがっていきます。 行く末は、誰もそのソースコードをメンテナンスできない状態になり、一からすべてを作り直すことになります。 直近のリリースでうまく動作することだけを考慮するのであれば、当期の人件費は下げられるかもしれません。 ぐちゃぐちゃなスパゲッティコードを組んで、とりあえず動くように継ぎはぎを繰り返すことで完成させればよいのですから。 でも、長期的な視点でビジネスを考えていくのであれば、本当はソースコード自体のメンテナンス性（静的品質）を向上させることにこそ力を入れるべきなのです。
緊急度と重要度のマトリックスに強引に当てはめると下記のようなイメージでしょうか。
緊急度
「高」 緊急度
「低」 重要度
「高」 静的品質 重要度
「低」 動的品質 直近のリリースの重要度ももちろん高いと思いますが、ここでの重要度とは、あくまで長期的な視点でのビジネスインパクトが大きいという意味で捉えてください。
静的品質を高めるには ソフトウェアの静的品質を高めていくには、現在作成されているソースコード自体の品質が高いかどうかを判断できなければいけません。 そのために活用できるのが静的解析 (static analysis) ツールに分類される下記のようなツールです。
PMD Checkstyle FindBugs 各言語用 Lint Coverity（有料） Fortify（有料） これらのツールはソースコード上の不適切な設計（可読性が悪い、保守性が悪い、効率が悪い、危険な設計など）をレポートしてくれますが、検出の得意・不得意がありますので、可能な限り多くのツールを使用して静的解析を実施しておくべきです。 これらの解析はソースコードを修正するたびに頻繁に実行する必要がありますので、１ステップで実行できるように自動化してください（Java であれば Gradle、Ruby であれば rake といったビルド自動化のためのツールを使用します）。 複数メンバで開発を行っている場合は、中央リポジトリにソースコードをコミットする前に、警告件数が増加していないかを必ず確認するようにルールを徹底します。 中央サーバにコミットされたソースコードに関しては、CI サーバ（Jenkins など）などで自動的に静的解析を実行するようにし、警告件数が増えた場合にはメールによる通知を行うようにしておきましょう。
静的解析ツールを導入するのは早ければ早いほどよいです。 プロジェクトの終盤で急に導入すると、何千件もの警告が一気に出て面食らってやる気がそがれる可能性があります。 できれば初期の段階から解析を実施するようにして、警告件数は常に 0 件近くをキープするようにしましょう。 特に下記のような複雑度やコードサイズに関する警告は、早い段階からつぶしておかないと、どんどん症状が悪化していきます。一度こういった複雑度に関する警告が出ている状態になってしまうと、それ以上に複雑度が上がった際に警告数の増加という形で気付くことができなくなってしまうからです。
１ファイル、１クラスあたりの行数に関する警告（例: ExcessiveClassLength） １メソッドあたりの行数に関する警告（例: PMD の ExcessiveMethodLength） コードの複雑度に関する警告（例: PMD の CyclomaticComplexity、NPathComplexity） クラスの責務割り当てに関する警告（例: PMD の GodClass） そして、会社などの組織でソフトウェアを開発している場合に最も重要なのは、こういった解析に基いて計算されたソフトウェアの静的品質によって報酬の額を決めるということです。 静的品質によるビジネスインパクトが大きいことを考えれば、これはまっとうな考え方です。 メンテナンス性の悪いコードをコミットすることは、工数的な負債だけを将来にまわして楽をするということですから、その時点で報酬を減額しなければつじつまが合いません。 間違っても、その負債を引き継いだメンバから報酬をカットするようなことがあってはいけません（その負債を解消するために工数を取られ、目に付く新しい機能を実装する時間がなくなってしまうため、まるで成果が出ていないかのように見えてしまうものです）。</description></item><item><title>Enterprise Architect の図をシンプルにして Power Point に貼り付ける</title><link>https://maku77.github.io/p/2vpskj3/</link><pubDate>Tue, 21 Jun 2016 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/2vpskj3/</guid><description>（下記は Enterprise Architect バージョン 12.0.1215 で確認しています）
Enterprise Architect の図を Power Point に貼り付ける Enterprise Architect で作成したダイアグラムなどは、Power Point などにドラッグ＆ドロップで簡単に貼り付けることができます。 あるいは、メニューから画像ファイルに出力することもできます。
ダイアグラム → イメージをファイルに保存 (Ctrl + T) Power Point などに張り付けるのであれば、ベクタ形式の EMF などで出力しておくと、拡大表示した時にもきれに表示されるようになります。
シンプルなダイアグラム表示にする グラデーションを Off にする Enterprise Architect で作成するクラス図などの各要素は、デフォルトでグラデーションが入ったり、シンプルではありません。 下記のようにすると、グラデーションを Off にすることができます。
ツール → ユーザのオプション → ダイアグラム → グラデーションと背景 「要素の背景色」の「グラデーションの向き」を ＜なし＞ に設定 あるいは、ダイアログのテーマとして、「モノクロ」などを選択する方法もあります。
ツール → ユーザのオプション → ダイアグラム → テーマ 「ダイアグラムのテーマ」で「モノクロ（印刷用）」を選択 ダイアグラムの外枠を Off にする クラス図の各要素を Power Point に貼り付けると、デフォルトではクラス図の外枠（ダイアグラムフレーム）まで表示されてしまいます。これを Off にしておけば、各クラス要素だけをシンプルに貼り付けることができるようになります。
ツール → ユーザのオプション → ダイアグラム 「ダイアグラムフレーム」のチェックを外す</description></item><item><title>ゴッドクラス (God Class) とは</title><link>https://maku77.github.io/p/eh73hkg/</link><pubDate>Fri, 18 Dec 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/eh73hkg/</guid><description>PMD などの静的解析ツールで、God Class（ゴッドクラス） という警告が出ることがあります。
Possible God class (WMC=52, ATFD=76, TCC=0.022058823529411766). God Class は、本来あまり関連性を持たせるべきではない多くのクラスを参照、結びつけてしまっているクラスであり、神のように全体を制御しているクラスを指します。 クラスの責務分割がうまくいっていない場合に、このような多くの責務を持つクラスができてしまうことがあります。 上記の警告が出た場合は、クラス内の処理を適切なまとまりで別のクラスに分割する、といったリファクタリングが必要であることを示唆しています。
あるクラスが God Class になっているかどうかを定量的に判断できるようにした WMC、ATFD、TCC というメトリクスが、Michele Lanza と Radu Marinescu の『Object-Oriented Metrics in Practice』 の中で紹介されています。
これらの値が、下記の条件をすべて満たすと、God Class とみなされます。
WMC ≧ VERY_HIGH (= 47) ATFD ＞ FEW (= 5) TCC ＜ 1/3 (= 0.333&amp;hellip;) それぞれのメトリクスは、下記のような意味を持っています。
WMC: Weighted Method Count (Weighted Method per Class) WMC は、クラス内のメソッドの複雑度の合計値です。 WMC が高いということは、アプリケーションへの依存度が高く、再利用性、メンテナンス性の悪いクラスであることを示します。 逆に、WMC が低いということは、明示的な分岐などが少なく、オブジェクト指向における多態性（ポリモーフィズム）を活かした設計ができているクラスと言えます。 複雑度の計算方法は色々あるようです。
McCabe&amp;rsquo;s Cyclomatic Complexity of the method Lines of Code in the method 1 for each method (unweighted WMC) PMD のコードを見る限り、1 番の Cyclomatic Complexity が採用されており、下記のような要素の合計値で求められるようです。</description></item><item><title>アプリ内の名前空間（Java のパッケージ階層）に迷った時のヒント</title><link>https://maku77.github.io/p/medwvff/</link><pubDate>Tue, 15 Dec 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/medwvff/</guid><description>あいまいなパッケージ分割 みなさんは、アプリケーション内の名前空間をどういったポリシーで分けていますか？ （ここでは Java プログラムのパッケージ分割について考えることにしましょう） パッケージの分割方法、命名方法は、ベテランのプログラマでも悩むところです。
例えば、MyApp (com.example.myapp) というアプリケーションのルートパッケージが、下記のように分割されていたとします。
com.example.myapp + optionmenu + view + ... このパッケージ分割方法には少々問題があるということにすぐに気付いた方は、普段から保守性を意識したコーディングを行えている人だと思います。 上記のパッケージ名からは、次のようなことを想像できます。
オプションメニューという機能を構成するクラスは optionmenu パッケージに格納すればよさそうだ。 UI 系のコンポーネントは view パッケージに格納するのだろう。でも、オプションメニューを構成する UI コンポーネントは optionmenu に入れるの？それとも view に入れるの？ ようするに、パッケージ分割のポリシーがあいまいだということです。 optionmenu というパッケージは、**「アプリ内の部分的な機能」という側面 (aspect) に注目して分割しており、一方で、view というパッケージは、「クラスが提供する機能の種類」**という側面で分割してしまっています。
そもそも、物事は複数の側面（アスペクト）から捉えられるのに、名前空間は階層構造という概念でしか分割できないというところに制約があります。 ブログなどのシステムでは、タグという機能によって、記事に対して横断的なラベルを付けらるのですが、プログラミングの名前空間の世界には、このような機能は今のところありません。 どのような側面によりパッケージ分割するかのポリシーを決めておかないと、先の例のようなあいまいなパッケージ分割が行われることになってしまいます。 重要なのは、新しいクラスを作成するときに、どのパッケージに格納すべきかが直感的に分かるようなパッケージ分割のポリシーを決めることです。
パッケージ分割のヒント ここでオススメするのは、**「アプリ内の部分的な機能」**を基準にパッケージ分割していくという方法です。 例えば、アプリケーションのルートパッケージを下記のように分割します。
com.example.myapp + feature（あるいは function など） + common + main（あるいは app など） + ... feature パッケージには、アプリケーションを構成する部分的な機能（フィーチャ）を提供するためのパッケージ、クラスを格納する（例: feature/opetionmenu）。 common パッケージには、上記の複数のフィーチャから共通で使用するユーティリティクラスなどを格納する。 main パッケージには、アプリケーションを動作させるのに必須なクラスを格納する（起動シーケンスに関わる部分など）。モジュール化を意識するのであれば、main パッケージはできるだけ小さく維持すること。 このように分割しておけば、例えば、オプションメニュー機能の UI を構成するクラスは feature/optionmenu パッケージ以下に格納すればいいんだな、とか、一方で共通で使用する UI モジュールは common/view パッケージ以下に格納すればいいんだな、と一発で分かるようになります。 この分割方法は、複数メンバから構成されるチームで 1 つのアプリケーションを作っていくときに威力を発揮します。 ある機能を担当するメンバは、feature 以下の機能用パッケージでの修正に集中し、必要に応じて common パッケージにある共通クラスを利用する、というように作業範囲を明確に絞り込めるようになります。</description></item><item><title>テストピラミッドを意識してテストの自動化を進める</title><link>https://maku77.github.io/p/y4ezh5u/</link><pubDate>Thu, 24 Sep 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/y4ezh5u/</guid><description>Mike Cohn が『Succeeding with Agile』で紹介した test automation pyramid というものがあります。 テストの自動化を進めるときは、このような比率になるように構築していくと、効率のよいテストを行えるようになります。
一言でいうと、UI のテストと比べ、ユニットテストの方が費用対効果 (ROI: Return on Investment) が高いということです。 ヒューリスティックな要素が入り込む End-to-End のテストは、頑張って自動化しても、思ったほどの効果が得られないことが多くなります。 テスト記述にかかるコスト、メンテナンスにかかるコストなどを総合的に判断すると、ユニットテストの比率を最も大きくし、その次に統合テスト、最後に End-to-End (UI) テストの順になるようにテスト配分を考えるべきです。 Google も下記のような比率で考えるとよいといっています。
10%: UI test (end-to-end test) 20%: Integration test (components and services) 70%: Unit test ごく当たり前のように感じる構成ですが、開発の現場でよく見られるのは、テスト専門チームによるテストに頼ってしまう逆ピラミッド型 (inverted pyramid/ice cream cone) の構成です。
70%: UI test (end-to-end test) 20%: Integration test (components and services) 10%: Unit test リファクタリングの技術、ユニットテストの技術を向上させ、理想的なピラミッド型のテスト配分に近づけていくことで、ソフトウェアの品質は上がっていきます。</description></item><item><title>プロジェクト内での null の扱い方をルール化する</title><link>https://maku77.github.io/p/euk9dzr/</link><pubDate>Wed, 16 Sep 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/euk9dzr/</guid><description>Java のような null を簡単に扱える言語では、プロジェクト内で null の扱い方を統一しておかないと、NullPointerException のような不具合が多発します（これが Java の大きな欠点ともいえます）。 一方で、C++ などには「参照」という NULL でないことを保証する仕組みが言語的に備えられています。
コード内に null チェックが多いとコードの見通しが悪くなるだけでなく、実行パフォーマンスも悪くなります。 言語として Java などを採用するプロジェクトでは、下記のように null の扱い方に関するルールを定めておきましょう。 パフォーマンスに問題がない場合は null フリーなコードを目指すことをお勧めします。
null の扱いに関するルールの例 API ドキュメントに特に記載がない場合は 「パラメータには null を渡せない」 こととする null を渡せる場合は明確にドキュメントに記載し、どんな作用があるのか分かるようにすること メソッドの内部で不要なパラメータの null チェックをしないこと API ドキュメントに特に記載がない場合は 「null を返すのは禁止」 とする どうしても null を返さなければいけない場合は、必ずドキュメントやアノテーションで記載すること（null を返さない場合でも、アノテーションなどで表現しておくのが望ましい） リストや配列を返すメソッドは「null を返さずにサイズ 0 のオブジェクトを返す」こと（空リストを返すのか null を返すのかはドキュメントで明示すること） リスト以外のオブジェクトを返すメソッドでは「不用意に null を返さず Null Object を返す」ことを検討すること null を返さないことが分かっているメソッドの戻り値に対して、不要な null チェックをしないこと アノテーションを利用する 例えば、Android では、@NonNull や @Nullable といったアノテーションが用意されており、パラメータの null の扱い、戻り値の null の扱いを明確に示すことができます。</description></item><item><title>単位を明確にする</title><link>https://maku77.github.io/p/84n7rxj/</link><pubDate>Thu, 25 Jun 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/84n7rxj/</guid><description>時刻や距離、重さなど、その単位が重要な場合は、名前から単位が分かるように命名しましょう。 パラメータに関しては、ドキュメンテーションコメントで説明しておくこともできますが、コメントではなくてシンボル名から単位を読み取れるのが理想的です。
long duration; // NG long durationInMillis; // Good public int convertTimeToPixel(long time); // NG public int convertMillisToPixel(long millis); // Good</description></item><item><title>時制や単数形・複数形を考慮して命名する</title><link>https://maku77.github.io/p/tdmxx2s/</link><pubDate>Thu, 25 Jun 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/tdmxx2s/</guid><description>関数名や、変数名は、英語の文法と同様に、時制と単数形・複数形にも気を配るようにしましょう。 複数のオブジェクトを含む配列なのに変数名が単数形になっていたり、真偽値を返すメソッドだからといって、すべて isXxx のような名前にしていたのでは、読みやすいコードにはなりません。
例: 複数の要素を持つ可能性があるのであれば複数形、あるいは xxxList のような命名をする Bitmap[] thumbnails; // Good Bitmap[] thumbnail; // NG 例: 真偽値は isXxx という形にこだわらず、意図の分かる命名をする boolean canShowTitle; // Good（タイトルを表示可能な状態だということが分かる） boolean shouldShowTitle; // Good（タイトルを表示すべきということが分かる） boolean isTitleEnabled; // OK（何が可能なのか分かりにくい） boolean isShowTitle; // NG（表示すべきということ？表示されていること？） 例: 時制を意識した命名をする bool areAllColorsLoaded; // Good（現在の状態を表している） bool wasNameDeletedBeforeExit; // Good（過去の変化を表している） bool isDisplayAddress; // NG（状態なのか、可能性なのか、何を表しているのか分からない。そもそも文法がおかしい）</description></item><item><title>肯定形で表現する</title><link>https://maku77.github.io/p/gosywwh/</link><pubDate>Tue, 23 Jun 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/gosywwh/</guid><description>真偽値を表すのであれば、否定形よりも肯定形で統一しましょう。 例えば、disabled ではなく enabled を、hidden/invisible ではなく shown を使用します。
boolean isInvisible(); // NG（isVisible とすればよい） boolean isHidden(); // NG（同上） setHideFlag(boolean shouldHide) // NG（単純に show とすればよい） boolean isNotDisplayed; // NG（反転させなくてよい） setVisibility(boolean visible); // OK（show() と hide() を用意するのも OK） show() / hide() // OK</description></item><item><title>静的チェックのレベルはプロジェクト初期に厳しくする</title><link>https://maku77.github.io/p/74qmru8/</link><pubDate>Tue, 16 Jun 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/74qmru8/</guid><description>大規模な開発チームや、スキルレベルの異なるメンバが含まれる開発チームでは、コード品質を一定以上に保つために Checkstyle や FindBugs などの静的解析ツールを導入するのはほぼ必須といえます。
こういった静的解析ツールは、プロジェクト開始時から導入しておくべきです。 開発の途中で静的解析のチェックレベルを厳しくしても、対応が容易ではないことがあります。 例えば、1 ファイルあたりの行数が何千行にも膨れ上がってしまってから、行数の制約を加えても、すぐには修正ができません。 長期的な開発の過程でメンテナンス性を損なわないようにするためのチェック項目は、コードが健全なうちにチェックレベルを上げて有効にしておきましょう。
例えば、下記の Checkstyle 定義では、ファイルあたりの行数が 1000 行を超えるとエラーになるように定義しています。
checkstyle.xml &amp;lt;module name=&amp;#34;Checker&amp;#34;&amp;gt; ... &amp;lt;module name=&amp;#34;FileLength&amp;#34;&amp;gt; &amp;lt;property name=&amp;#34;severity&amp;#34; value=&amp;#34;error&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;max&amp;#34; value=&amp;#34;1000&amp;#34;/&amp;gt; &amp;lt;/module&amp;gt; ... 静的解析の段階でエラーにすることで、メンテナンス性を下げるコードがコミットされることを防ぐことができます。</description></item><item><title>無駄な汎用性ではなくシンプルな設計を (YAGNI)</title><link>https://maku77.github.io/p/6ybc6rp/</link><pubDate>Mon, 15 Jun 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/6ybc6rp/</guid><description>YAGNI (You ain&amp;rsquo;t gonna need it) (You aren&amp;rsquo;t going to need it) というのは、将来のためにあらかじめ入れておいた実装が、結局は使われないことを言っています。
オブジェクト指向設計が登場した頃は、継承やポリモーフィズムといった仕組みを活かして、汎用的な設計をすることを美とする傾向がありました。 しかし、現在のソフトウェア開発では、短いサイクルでのリリースや、頻繁な仕様変更に対応しながら開発を進める必要があり、将来を予測して汎用的な実装を行っておくことは困難になってきています。
アジャイルな開発では、使うかどうか分からない機能や、無駄な汎用性を持たせた実装を行うことを良しとしません。 今必要な実装をシンプルに、確実に実装することに集中します。 シンプルで分かりやすい設計になっていれば、将来修正が必要になった場合でも比較的容易に変更を行うことができ、トータルのコストも少なくなるというわけです。
参考: YAGNI - Wikipedia</description></item><item><title>可変オブジェクトのメンバ参照を返さない</title><link>https://maku77.github.io/p/f3m87vq/</link><pubDate>Wed, 27 May 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/f3m87vq/</guid><description>メンバ変数として可変オブジェクト (mutable object) を持っているクラスが、getter メソッドでその参照をそのまま返してしまうと、クラス外部からオブジェクトの内容を変更されてしまいます。 プライベートなメンバを外部から守るためにカプセル化しているはずなのに、これでは実際には何も守られておらず、外部からそのクラスの振る舞いを壊されてしまいます。
例えば、下記の Program クラスは、メンバ変数として Date オブジェクトを持ち、getter メソッドでその参照を返しています。
import java.util.Date; public class Program { private final Date startTime = new Date(); public Date getStartTime() { return startTime; } } Java の Date オブジェクトには、setTime() メソッドが存在するため、可変オブジェクトです。 可変オブジェクトの参照を外部から取得できるようにすると、その参照を通して値を変更されてしまいます。
Program program = new Program(); System.out.println(program.getStartTime()); // Wed Jan 1 01:11:54 JST 2014 // メンバ変数への参照を取得し、値を書き換える Date date = program.getStartTime(); date.setTime(date.getTime() + 1000000); System.out.println(program.getStartTime()); // Wed Jan 1 01:28:34 JST 2014（破壊された） このような外部からのオブジェクト破壊を防ぐには、プリミティブな値、あるいは不変オブジェクト (immutable object) の参照を返すようにします。</description></item><item><title>不具合修正に対する向き合い方</title><link>https://maku77.github.io/p/wiy8w8n/</link><pubDate>Tue, 26 May 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/wiy8w8n/</guid><description>不具合そのものではなく、不具合混入の根本原因を突き止める ソフトウェアの実装に不具合が見つかった時、正しく動作するように修正するだけでは不十分です。 継続的に設計を改善していくためには、どうしてそのような不具合となるコーディングを行ってしまったのか、その根本的な原因を突き止め、その原因を取り除いていく必要があります。 表面的な不具合の修正を繰り返しているだけでは、不具合を生みやすい構造が改善されないため、ソフトウェアの品質はいつまでたっても上がらず、不具合修正の工数だけが増えていきます。
不具合を分析するときは、表面化した不具合（結果）にだけ注目するのではなく、不具合混入の根本原因を探りましょう。 下記は、典型的な不具合のパターンと、それぞれどのような根本原因が潜んでいるかの例です。
パターン１: API の使い方を間違えて不具合が入った 大きなプロジェクトでは、他のメンバが作成した API を使用することが多くなるため、このパターンによる不具合は多く発生します。 実装者が API の使用方法をまったく調べずに使ってしまったということも考えられますが、突き詰めていくと、下記のような原因が見えてきます。
変数名やメソッド名から実際の振る舞いが想像できなかった API ドキュメントの記載があいまいで正しい呼び出し方がわからなかった パラメータの型が汎用的すぎて（int 型など）、想定外の値を渡してしまった このような原因が考えられる場合は、不具合そのもののコードを修正するだけでなく、根本原因となった既存のコードを改善するようにしましょう。それが本当の品質改善です。
変数やメソッドに誤解を招くような名前が付けられているのであれば、意図が正しく伝わるような名前に変更しましょう。 ドキュメンテーションコメントが不十分であれば、誰が読んでも正しく解釈できるように説明文を変更します。 メソッドにテストコードがなければ追加し、メソッドの振舞いをより明確にします。 パラメータが int や String といったプリミティブ型で定義されている場合は、列挙型に変更することで、誤った使われ方を防ぐことができるでしょう。
パターン２: 不具合を修正したら別の不具合を埋め込んでしまった いわゆるエンバグというものです。 複雑なメソッドを修正する場合にはエンバグのリスクは付き物です。 エンバグしてしまった原因としては下記のようなことが考えられます。
修正を入れたことにより、あるメソッドの戻り値が想定外の値になっていることに気付かなかった ある定数値を変更したときに、連動して変えなければいけないコードがあることに気付かなかった 修正部分の周囲のコードの意味が分からず、そこに与える影響に気付かなかった エンバグの特徴としては、不具合の原因がもともとのコードにあることが多いことが挙げられます。 もともとのコードのメンテナンス性が悪ければ、修正時に別の不具合が入ってしまうことは避けられません。 既存のメソッドに副作用が出てしまうことを気付けなかったのは、そのメソッドにテストコードがなかったからです。 テストコードを追加し、間違った修正をしてしまった場合に、その場で気が付けるようにしましょう。
DRY 原則に基けば、同一の値を持つ定数値を、複数個所で管理しなければいけないような設計は改めるべきです。 とはいえ、設計プロセスやアーキテクチャ上の都合で、重複した記述を防げないこともあります（ファイルを分散して置かなければいけないとか）。 そのような場合は、連動して変更しなければいけないコードすべてに、相互のポインタを記述しておくとか、コードを自動生成するなどの仕組みを考えます。
既存コードの設計が複雑で、皆が容易に理解できないようであれば、そのコードは優先的にリファクタリングを進めるべきです。 メソッドが巨大すぎるのであれば分割し、ドキュメンテーションコメントを分かりやすく記述します。 第三者が読んだときにすぐに理解できるようなコードになるまで改善しておかなければいけません。 そうすることで、将来的にそのコードを編集するときにエンバグしてしまうリスクを低減できます。
パターン３: 要求通りの機能になっていなかった これは実装者がちゃんと要求や仕様を理解できているかの問題になります。 ソフトウェア設計は、ある仕様に基いて進めていくことになりますが、その仕様に対する理解度に差が出てしまう原因はいろいろ考えられます。
仕様書を読んでいない 仕様書を読んで理解したつもりになっていたけれど解釈が間違っていた 仕様書を読んでも理解できないので想像で実装していた 仕様書がない そもそも仕様書を読まずに実装していたとなると、「ちゃんと読め！」と、頭ごなしに実装者を攻めてしまうことがありますが、まずはなぜ仕様書を読まなかったのかにフォーカスするのがよいでしょう。 仕様書が簡単にアクセスできるところにアップロードされていないのではないか？ 仕様書を読み込むための工数が確保されていないのではないか？ 仕様書内でローカルな専門用語を使いすぎていて読んでも理解できないのではないか？ 仕様書が読みにくいのではないか？ などなど、より上位に問題が潜んでいるかもしれません。
仕様書をじっくりと読んだにもかかわらず認識の齟齬が出てしまう場合は、仕様書自体に問題があることが多いです。 仕様書の記載方法に関する研修を受けたり、チーム内で仕様書の記載に関する改善ブレストなどをするとよいでしょう。
仕様が複雑な場合は、コード内に仕様書へのリンクを埋め込んだり、詳しいドキュメンテーションコメントを記述しておかなければいけません。 将来的にそのコードをメンテナンスする人のことを考えれば、それがどれだけ重要なことか分かるはずです。 そのコードを実装するときに特定の資料が必須であったのであれば、その資料がアップロードされているサーバの URL を記載しておきましょう。 また、その複雑な仕様が、ユーザにとっても複雑なものになっているのであれば、仕様自体をシンプルにできないか見直すべきです。</description></item><item><title>設定値の伝搬タイミングを意識する</title><link>https://maku77.github.io/p/28izof5/</link><pubDate>Thu, 21 May 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/28izof5/</guid><description>設定値によって複数のオブジェクトの振る舞いを変える可能性のあるアプリケーションは、その設定値を各オブジェクトが参照するタイミング、振る舞いへと反映するタイミングに整合性を持たせることを意識して設計する必要があります。
反映タイミングを意識しないといけないものには、下記のようなものがあります。
現在時刻の更新 言語設定 (Locale) の変更 ウィンドウサイズ、フォントサイズの変更 例えば、現在時刻の変化によってリアルタイムに表示を変えるようなアプリケーションは、各 View コンポーネントがそれぞれの現在時刻情報を持ってしまうと、あるコンポーネントは現在時刻の情報を表示しているのに、他のコンポーネントは一分前の情報を表示している、といった不整合が起こります。 このような、アプリケーション全体に同時に反映すべき情報は、その設定値の変化をコールバックで直ちに知る仕組み、あるいは、メッセージ（Android なら Intent など）による通知の仕組みを導入することで、一貫性を崩すことなく伝搬することができます。</description></item><item><title>よいツールの条件</title><link>https://maku77.github.io/p/deia4to/</link><pubDate>Sun, 17 May 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/deia4to/</guid><description>まくが考えるよいツールの条件は下記を満たすものです。
インストールが簡単 ユーザインタフェースがシンプル 拡張・カスタマイズが容易 ドキュメントにアクセスしやすい ドキュメントがわかりやすく包括的 ソースコードがわかりやすい 自分でツールを作るときは、常にこういったことを忘れないように気をつけるとよいです。</description></item><item><title>ぐちゃぐちゃなコードしかないチーム／プロジェクトに配属された場合のポジティブ思考</title><link>https://maku77.github.io/p/rtrb95n/</link><pubDate>Sun, 26 Apr 2015 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/rtrb95n/</guid><description>どうしようもないコードがたくさんある、読んでも意図がわからないコードがいっぱい、というプロジェクトに配属されると気が滅入りそうになります。 でも嘆いているだけでは何も改善しません。 そんなときこそポジティブシンキングです。
リファクタリングの技術を磨くことができる！ レガシーコードをテスト可能にする技術を磨くことができる！ ダメなところ（メンテナンス性、速度、メモリ、潜在不具合）を見つけるソフトを使いこなせるようになる！ 構造を見直して高速化する技術を磨くことができる！ 分かりにくいコードをデバッグする技術を磨くことができる！ と考えれば、ダメダメなコードも自分の成長のための題材なんだと捉えられるようになります。 現在の環境の中でいかに成長できるのかを考えましょう。</description></item><item><title>Jenkins サーバの設定ファイルの場所</title><link>https://maku77.github.io/p/4zwxw7q/</link><pubDate>Tue, 08 Jul 2014 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/4zwxw7q/</guid><description> *.deb パッケージでインストールした場合 /etc/defasult/jenkins *.rpm パッケージでインストールした場合 /etc/sysconfig/jenkins Windows インストーラ（msi パッケージ）でインストールした場合 インストールディレクトリの jenkins.xml</description></item><item><title>お試しインスタンスとして Jenkins サーバを起動する (jenkins.war)</title><link>https://maku77.github.io/p/iscaefa/</link><pubDate>Tue, 08 Jul 2014 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/iscaefa/</guid><description>下記のように、JENKINS_HOME や HTTP ポート番号を指定して jenkins.war を起動することで、お試しの Jenkins サーバを起動することができます。 未知のプラグインのインストールを試してみるときや、設定を大きく変更してみたいときに便利です。
$ java -DJENKINS_HOME=/path/to/jenkins_home jenkins.war --httpPort=8081</description></item><item><title>CPD でコードクローンを発見する</title><link>https://maku77.github.io/p/q4n32h5/</link><pubDate>Sun, 29 Jun 2014 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/q4n32h5/</guid><description>CPD とは PMD (A source code analyzer) という静的解析ツールのパッケージに含まれている cpd コマンド (Copy/Paste Detector) を使用すると、ソースコードに含まれているコードクローンを簡単に探し出すことができます。 プロジェクトの規模が数万行を超えてきたときに、リファクタリングすべき箇所を探すための強い味方になります。
下記のように、主要な言語はほとんど対応しています。
C++ C# Fortran Go Java JavaScript JSP PHP PL/SQL Ruby XML and XSL インストール PMD/CPD のダウンロード https://pmd.github.io/ からアーカイブ（pmd-bin-5.2.0.zip など）をダウンロードして、適当なディレクトリに展開します。
Windows の場合 Windows の場合は、展開したディレクトリにある bin ディレクトリにパスを通しておけば、どこからでも cpd コマンドを実行できるようになります。
Linux の場合 Linux の場合は、bin/run.sh という、統一された入口として使用するシェルスクリプトが用意されているので、デフォルトでは bin/run.sh cpd のように実行しなければいけません。cpd というコマンドとして alias 定義しておくのがよいでしょう。
.bash_profile alias cpd=&amp;#39;/path/to/pmd-bin/bin/run.sh cpd&amp;#39; 実行方法 下記のように実行すると、src_dir ディレクトリ以下のソースコードに関して、コードクローンの検出を行います。
C:\&amp;gt; cpd --minimum-tokens 50 --files src_dir &amp;gt; results.txt オプションの --minimum-tokens の値を小さくすると、クローン検出の閾値が下がるので、より多くの箇所を検出するようになります。</description></item><item><title>パッケージ管理ツールいろいろ</title><link>https://maku77.github.io/p/g3cj5mi/</link><pubDate>Sun, 25 May 2014 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/g3cj5mi/</guid><description>Mac OSX 用のパッケージ管理 ツール名 コマンド パッケージインストール先 メモ MacPorts port /opt/usr システムにインストールされているコマンドに依存しないようにパッケージ管理するため、依存関係が多いとインストールに時間がかかる。パッケージインストールには管理者権限が必要 (sudo)。 Homebrew brew /usr/local システムにインストールされているコマンドをなるべく使用するように動く。一般ユーザ権限でパッケージインストール可能。Ruby で実装されている。 Fink fink /sw Debian の apt をベースにしている。 Gentoo Prefix emerge ~/Gentoo Gentoo の portage をベースにしている。Mac OSX 専用ではない。管理者権限不要。 各言語のバージョン切り替え ツール名 コマンド 環境インストール先 メモ GVM (Groovy enVironment Manager) gvm ~/.gvm 複数バージョンの Groovy を切り替えて使用するためのツール（Gaiden/Groovy/Grails/Griffon/Gradle などの切り替えもサポート）。その名の通り、RVM にインスパイアされて作られた。 RVM (Ruby Version Manager) rvm ~/.rvm 複数バージョンの Ruby を切り替えて使用するためのツール。 各言語のモジュール（パッケージ）管理 ツール名 コマンド パッケージインストール先 メモ NPM (Node Package Manager) npm ./node_modules Node.</description></item><item><title>XML の名前空間について</title><link>https://maku77.github.io/p/r8vjhx2/</link><pubDate>Sun, 31 Mar 2013 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/r8vjhx2/</guid><description>名前空間を宣言する XML の名前空間を宣言するには、任意の要素の開始タグで、
xmlns:&amp;lt;NamespacePrefix&amp;gt;=&amp;#34;&amp;lt;NamespaceName(URI)&amp;gt;&amp;#34; のような属性を指定します。この属性を指定した要素以下の要素でその名前空間を使用できるようになります。属性を宣言した要素自体でも使えるので、XML の root 要素で名前空間を宣言すれば、全ての要素でその名前空間が使えることになります。
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; ?&amp;gt; &amp;lt;b:books xmlns:b=&amp;#34;http://example.com/dtd/books&amp;#34;&amp;gt; &amp;lt;b:book&amp;gt; &amp;lt;b:title&amp;gt;Title 1&amp;lt;/b:title&amp;gt; &amp;lt;b:author&amp;gt;Author 1&amp;lt;/b:author&amp;gt; &amp;lt;/b:book&amp;gt; &amp;lt;/b:books&amp;gt; 上記の XML 文書の例では、Namespace prefix（名前空間接頭辞）は b で、Namespace Name (URI) は http://example.com/dtd/books が指定されています。 名前空間を使用する時は、例を見れば明らかですが、&amp;lt;NamespacePrefix&amp;gt;:&amp;lt;LocalName&amp;gt; のように要素名を指定します。
名前空間名の URI が指すリソースは存在しなくてよい 名前空間名として指定する URI は、あくまで一意な名前を指定するものであって、その URI が示す先に、何らかのリソースファイルが存在している必要はありません。
名前空間の接頭辞に使えない名前 要素名と同様に、名前空間の接頭辞 (Namespace prefix) にも、xml で始まる名前は付けられません。大文字にしてもダメです。例えば、以下のような Namespace prefix はすべて NG です。
名前空間プレフィックスの NG 例 xml_prefix xmlPrefix XmlPrefix XML_Prefix 名前空間の接頭辞の上書き 親要素で既に宣言されている Namespace prefix を子要素で宣言すると、その prefix は上書きされます。ただし、その子要素より上位の要素では、親要素の Namespace prefix の宣言が使用されます。
デフォルトの名前空間 名前空間を宣言するときに、接頭辞 (prefix) を省略して宣言すると、デフォルトの名前空間 (default namespace) の宣言になります。デフォルトの名前空間が宣言された要素以下の要素は、prefix を特に指定しなくても、その名前空間に属するとみなされます。</description></item><item><title>GENA と SSDP プロトコルを理解する</title><link>https://maku77.github.io/p/wai79fn/</link><pubDate>Tue, 25 Dec 2012 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/wai79fn/</guid><description>概要 SSDP (Simple Service Discovery Protocol) は、LAN 内のデバイスが提供しているサービスを発見したり、サービスがネットワークに参加したことを通知したりするプロトコルです。 SSDP 自体はシンプルなプロトコルですが、DLNA などで使われている、機器発見プロトコルである UPnP の一部として利用されています。
SSDP は、以下のようなヘッダで始まる HTTP を拡張したような UDP ベースのプロトコルです。M-SEARCH メソッド は、ネットワーク内のサービスを SSDP クライアントが能動的に発見しにいくときに使用します。
SSDP メッセージのフォーマット M-SEARCH * HTTP/1.1 \r\n ヘッダ1: ... \r\n ヘッダ2: ... \r\n ヘッダ3: ... \r\n \r\n SSDP では、内部で GENA (General Event Notification Architecture) で定義されているメッセージフォーマットも使用しており、こちらは、
サービス（機器）がネットワークに参加した (ssdp:alive) サービス（機器）がネットワークから脱退した (ssdp:byebye) などの Notify をマルチキャストするために使用されます。
GENA メッセージのフォーマット NOTIFY * HTTP/1.1 \r\n ヘッダ1: ... \r\n ヘッダ2: ... \r\n ヘッダ3: ... \r\n \r\n SSDP では、以下のようなアドレス、ポート番号にメッセージを UDP でマルチキャストしましょうね、と決めています（ポート番号については、正式には UPnP の世界で決まっているのかも）。</description></item><item><title>Windows (MinGW) で GLUT を使用する</title><link>https://maku77.github.io/p/9nom8yj/</link><pubDate>Fri, 21 Dec 2012 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/9nom8yj/</guid><description>Windows の MinGW で GLUT を使用するには、freeglut を使用するのが簡単です。
https://www.transmissionzero.co.uk/software/freeglut-devel/ GLUT (freeglut) のインストール 「Download freeglut 2.8.0-1 for MinGW」といったところからアーカイブをダウンロードして展開すると、下記のようなファイル群が展開されます。
bin/ +-- freeglut.dll include/GL/ +-- freeglut.h +-- freeglut_ext.h +-- freeglut_std.h +-- glut.h lib/ +-- libfreeglut.a +-- libfreeglut_static.a それぞれ、以下のような位置にコピーすれば、インストール終了です。
DLL ファイル &amp;ndash; パス (%PATH%) の通ったどこか ヘッダファイル &amp;ndash; C:\MinGW\include\GL ディレクトリ lib ファイル &amp;ndash; C:\MinGW\lib ディレクトリ GLUT (freeglut) で HelloWorld GL/glut.h を使用したプログラムは、以下のようにビルドできます。
C:\&amp;gt; g++ main.cpp -lfreeglut -lopengl32 main.cpp #include &amp;lt;GL/glut.h&amp;gt; void display() { glClear(GL_COLOR_BUFFER_BIT); glBegin(GL_LINE_LOOP); glVertex2d(-0.5, -0.5); glVertex2d(0.</description></item><item><title>意外と知られていない XML 記述のルール</title><link>https://maku77.github.io/p/cht2cpg/</link><pubDate>Fri, 24 Aug 2012 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/cht2cpg/</guid><description>XML 文書を記述するときの意外と知られていないルールとして、下記のような定義があります。
XML 宣言の encoding 属性は省略できる。省略すると、encoding=&amp;quot;UTF-8&amp;quot; として扱われる。 xml で始まる名前は使ってはいけない（NG 例: &amp;lt;xmlRoot&amp;gt;, &amp;lt;XmlData&amp;gt;）。要素名にも属性名にも使ってはいけない。大文字を混ぜてもダメ。 タグ名に全角数字、半角カタカナは使ってはいけない。 文字参照で使うコード番号は、正確には Unicode ではなく ISO/IEC 10646 である。ただし、BMP (Basic Multilingual Plane) 領域は Unicode と同じなので、基本的に Unicode コードポイントとみなして構わない。</description></item><item><title>単体テスト、結合テスト、システムテスト、受入テストの関係を理解する</title><link>https://maku77.github.io/p/soeouhu/</link><pubDate>Wed, 15 Aug 2012 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/soeouhu/</guid><description>ソフトウェアのテストの話をするときは、どの粒度、観点からのテストの話をしているのかを認識することが大切です。 ここでは、単体テスト、結合テスト、システムテスト、受入テストの関係と全体像を掴みましょう。
システムテストと受け入れテスト 赤色の枠は、システム全体を示しています。 「システムテスト」は、システム全体を開発者視点でテストします。 「受入テスト」は、「システムテスト」と同様に、システム全体がテスト対象であり、テスト項目も多少かぶる部分がありますが、システム全体の振る舞いをユーザ（発注者）視点でテストするところが異なります。
単体テストと結合テスト 青色の丸と、緑色の丸は、システム内の構成要素を捉えるときの粒度の違いを示しています。 例えば、
青丸 &amp;ndash; クラス 緑丸 &amp;ndash; 複数のクラスから構成されたコンポーネント だと思ってください。 青丸の粒度の世界での「単体テスト」「結合テスト」もあるし、緑丸の粒度の世界での「単体テスト」「結合テスト」もあります。 「単体テスト」では、テスト対象を１つの要素に限定するため、問題を発見したときの問題個所の絞り込みが容易です。 「結合テスト」だけでは、単一要素に含まれる不具合を発見できないことがあります。 潜在的な不具合を防ぐには、「単体テスト」が重要な役割を果たすといえます。 大規模なシステムになるほど「単体テスト」の重要性は増してきますが、各モジュールの依存関係をあらかじめ考慮した上で設計を進めないと、「単体テスト」が行えないコードができてしまいます。 そうならないためにも、実装を進める前に、
テスト仕様（インタフェース仕様） テストコード の作成を行い、テストファーストで実装していくのが効果的です。 特に、複数人で開発を進める場合、テストを作成することで、最終的に完成するもののイメージを共有するという目的もあります。 ただし、テスト対象となる要素が単純な演算ライブラリのようなものでない限り、いざ、「単体テスト」を行う場面になったときに、他の要素との依存関係に悩まされるでしょう。 「単体テスト」は、あくまで単一の要素の動作を検証しなければならないので、他の要素の実装の進捗によってテスト結果が変わるようなことがあってはいけません。 そんなときに、以下のようなダミーモジュールを作成し、他の要素の動作を切り離します。
ドライバ &amp;ndash; テスト対象を起動、操作するためのモジュール スタブ &amp;ndash; テスト対象内部で呼び出している下位のモジュール ドライバ、スタブモジュールの作成自体が困難だと思った場合は、そのモジュールに責務を詰め込みすぎていないか、設計を見直すべき合図でもあります。
システムの実装は、下位モジュールからボトムアップで完成していくものなので、テストが成功していく順番も、「単体テスト」→「結合テスト」の順になります。 とはいえ、最終的なシステム全体の振る舞いを表現しているのは、より上位のテストです。 テスト仕様は、トップダウンで作っていくのが望ましいでしょう。</description></item><item><title>Tera Term のマクロで特定の文字列を検出して処理を実行する</title><link>https://maku77.github.io/p/qkxss6a/</link><pubDate>Tue, 19 Apr 2011 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/qkxss6a/</guid><description>Tera Term のマクロで、waitln 命令を使用すると、ターミナルに特定の文字列が出力されたことを検出することができます。 例えば、シリアル接続したデバイスなどからのメッセージを監視して、あるパターンに一致するメッセージを受信したときに任意の処理を行うことができます。
下記のサンプルマクロでは、シリアル接続された端末から system booted という文字列を受信したときに、Hello というメッセージを表示し、mycommand &amp;amp; というコマンドを実行しています。
auto_hello.ttl do while 1 timeout = 0 ;Timeout never occurs waitln &amp;#39;system booted&amp;#39; pause 1 dispstr #$0A #$0A dispstr &amp;#39;Hello&amp;#39;#$0A dispstr #$0A #$0A sendln &amp;#39;mycommand &amp;amp;&amp;#39; loop ところどころ出てくる #$0A というのは、改行することを表しています。</description></item><item><title>GoFのデザインパターン: Visitor パターン</title><link>https://maku77.github.io/p/458msi9/</link><pubDate>Sun, 10 Apr 2011 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/458msi9/</guid><description>GoF のデザインパターンのひとつである Visitor パターンは、オブジェクトの構造を変更せずに、オブジェクトの集合に対して新しい操作を追加するためのパターンです。
Visitor パターンの特徴 インタフェースの異なるオブジェクトを巡回することができる。Visitor オブジェクトは、各種要素を巡回しながら目的のデータを構築する。 巡回対象のクラスのカプセル化が破られることがある。 若干複雑。 単純なポリモーフィズムによる巡回ができる場合は、このパターンを使う必要はない。 Visitor パターンを使わない場合 例えば、HTML のノードリストを順番に処理しながら HTML テキストを構築することを考えてみます。 各ノード（テキストノードやリンクノードなど）を表すクラスは、保持するデータやインタフェースが異なるため、深く考えずに実装してしまうと次のような instanceof とキャストの組み合わせコードができてしまいます。
public String extractHtmlText() { StringBuilder results = new StringBuilder(); Node node = null; while ((node = nodeList.next()) != null) { if (node instanceof StringNode) { StringNode n = (StringNode) node; results.append(&amp;#34;&amp;lt;P&amp;gt;&amp;#34;); results.append(n.getText()); results.append(&amp;#34;&amp;lt;/P&amp;gt;&amp;#34;); } else if (node instanceof LinkNode) { LinkNode n = (LinkNode) node; results.append(&amp;#34;&amp;lt;A href=&amp;#39;&amp;#34;&amp;gt; + n.getUri() + &amp;#34;&amp;#39;&amp;gt;&amp;#34;); results.</description></item><item><title>共通鍵暗号化方式と公開鍵暗号化方式</title><link>https://maku77.github.io/p/xkoyxnh/</link><pubDate>Sun, 28 Nov 2010 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/xkoyxnh/</guid><description>共通鍵暗号化方式 用途 暗号化／複合化 &amp;ndash; 暗号化と複合化を同じ共通鍵（秘密鍵 Secret Key）で行う。 実装 DES (Data Encryption Standard) &amp;ndash; 1960年代。IBM。FIPS 46。暗号強度が低すぎる。鍵が 56 ビットなので、ブルートフォースアタックですぐに解読されてしまう。 3-DES (Triple DES) &amp;ndash; 1999年。IBM。AES までの繋ぎ。 AES (Advanced Encryption Standard) &amp;ndash; 2001年3月。米国商務省標準技術局(NIST)。FIPS 197 として公表。 公開鍵暗号化方式 用途 暗号化／複合化 &amp;ndash; 送信者が受信者の公開鍵 (Public Key) で暗号化し、受信者は自分の非公開鍵 (Private Key) で複合化する。 署名 &amp;ndash; 送信者が自分の非公開鍵で電子署名し、受信者が送信者の公開鍵で改変されていないことを確認する。公開鍵がそもそも偽造だと意味がないので、公開鍵を正しいものだと証明するための機関として、認証局 (CA) というものがある。 実装 RSA（Ronald Rivest, Adi Shamir, Leonard Adleman）&amp;ndash; 1977年。 DSA (Digital Signature Algorithm) &amp;ndash; 1991年8月。米国商務省標準技術局(NIST)。FIPS 186 として公表。1024 bits が一般的。 ECDSA (Elliptic Curve Digital Signature Algorithm) &amp;ndash; 楕円曲線暗号版の DSA。RSA や DSA よりも短い鍵長で、強い強度を持つという特徴がある。 Ed25519 (Edwards-curve Digital Signature Algorithm) &amp;ndash; エドワーズ曲線暗号。ECDSA よりも高速に処理できるという特徴がある。 「認証局 (CA)」は、鍵の所有者の情報と、その公開鍵を管理しており、公開鍵が偽造されていないことを「証明書 (Certificate)」を発行することで証明します。 「証明書」とは、ある公開鍵とその所有者情報を「認証局の非公開鍵で署名」したものです。 この署名により、認証局が発行している証明書がそもそも本物であるということを証明します。 ようするに、公開鍵暗号方式では、どこかの時点で公開鍵を無条件に信頼しなければいけなくて、その代表になるのが認証局ということです。 証明書の形式には X.</description></item><item><title>リソースは finally ブロックで閉じる</title><link>https://maku77.github.io/p/r2re7ux/</link><pubDate>Sat, 28 Aug 2010 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/r2re7ux/</guid><description>データベース接続に限らず、I/O 処理にかかわるオブジェクトを使用し終わった後は、通常はリソース解放するための明示的な close 処理が必要です。 例外機構をもつ言語において、close 処理は finally ブロック内で実行するのがセオリーです。 そうしないと、例外発生時に close が実行されないケースが出てきてしまいます。
このあたりの具体例は、下記のサイトでまとめられています。 この記事では、セマフォの解放も finally ブロック内で行うべきと記述されています。
Javaの理論と実践: 良いハウスキーピング習慣を身につける 例えば、Java の JDBC では、オープンした Connection オブジェクト、Statement オブジェクトを明示的に閉じる必要があります。 JDBC を使ったプログラミングでは、これらのオブジェクトの閉じ忘れによる不具合が非常に多いようです。 JDBC ドライバの実装はベンダによって様々なので、ある実装ではコネクションの閉じ忘れによってリークが発生するのに、別の実装では発生しなかったりすることがあります。 こういった事情により、潜在的なリソースリークの不具合が含まれていることに気付かないことが多いのです。 幸いにも、最近の静的解析ツールでは、このような DB コネクションの閉じ忘れを検出してくれるようになっています。
具体的な例として、JDBC の Connection オブジェクト、Statement オブジェクトを閉じるコードは以下のような try ～ finally 構成になっていなければいけません。 ここでは SQLException をメソッドの呼び出し元に伝搬させていますが、もちろんメソッド内でハンドルしてしまっても構いません。
public void doSomething() throws SQLException { Connection con = getConnection(); Statement stmt = null; try { stmt = con.createStatement(); ResultSet resultSet = stmt.executeQuery(&amp;#34;SELECT * FROM tbl&amp;#34;); // .</description></item><item><title>コメント内で使える特殊キーワード（XXX、TODO など）を理解する</title><link>https://maku77.github.io/p/5m9eowc/</link><pubDate>Wed, 29 Jul 2009 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/5m9eowc/</guid><description>FALLTHROUGH: 次の case へ処理を継続する /* FALLTHROUGH */ は case の終わりで意図的に break しないことを示します。 Lint ツールなどはこのキーワードを検出して、case 漏れ警告を抑制します。
switch (...) { case 1: ... /* FALLTHROUGH */ case 2: ... NOTREACHED: そこへは到達しない /* NOTREACHED */ は、関数の終わりなどに達しないことを示します。
void hoge() { while (...) { ... if (...) { return; } } /* NOTREACHED */ } XXX: 要確認 /* XXX */ は、正しいか分からないが、とりあえず動いていることを示します。
// XXX: このコードがあるとなぜか速度が上がる magic_function(100); FIXME: 修正の必要あり // FIXME: 過去の日付を入力しても落ちないように TODO: 将来拡張予定 // TODO: ヘッダに番組タイトルを表示する</description></item><item><title>TFTP の使い方（TFTP によるファイル転送）</title><link>https://maku77.github.io/p/46b5wxe/</link><pubDate>Mon, 25 May 2009 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/46b5wxe/</guid><description>TFTP の特徴 Trivial File Transfer Protocol の略。 https://www.ietf.org/rfc/rfc1350.txt 非常に軽量なので、ブートストラップ用のプロトコルとしてよく使われる。 TFTP クライアントを使ったファイル転送の例 例: ファイル取得 $ tftp 192.168.0.1 get sample.txt Transfer successful: 234 bytes in 1 second, 234 bytes/s 例: ファイル送信 $ tftp 192.168.0.1 put sample.txt Transfer successful: 234 bytes in 1 second, 234 bytes/s 例: バイナリモードで転送したい場合は -i オプション $ tftp -i 192.168.0.1 get sample.data</description></item><item><title>ダイナミック・ルーティング・プロトコルのメモ (RIP, OSPF, BGP-4)</title><link>https://maku77.github.io/p/gowvphv/</link><pubDate>Fri, 09 May 2008 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/gowvphv/</guid><description>RIP (Routing Information Protocol) 特徴 最も歴史があり、最も簡単で、多くのエンジニアが知っている。 小、中規模の WAN を介さないネットワークで使われる。 サポートしている機器が多い。 仕組み ルータが自身のルーティングテーブルをブロードキャストで隣のルータへ伝える、ということを繰り返してルーティングテーブルを伝播していく。 自分自身のルーティングテーブルは最初、メトリック値１としてブロードキャストする。ルーティングテーブルを伝播するごとに、ルーティングテーブルのメトリック値が＋１される。メトリック値が大きいほど、遠いルータだということが分かる。同じサブネットへの経路として複数のルータが選択できる場合、メトリック値が小さいもの（要するにルータのホップ数が少なく、近いもの）が選択される。 30秒ごとにルータはまわりのルータに情報を送信する（レギュラーアップデート）。あるルータのレギュラーアップデートを 6 回受信できない状態が続くと、そのルータに障害が発生したとみなされ、メトリック値 16 が設定され、さらに 4 回 RIP パケットの応答がない場合はルーティングテーブルからそのルータの情報が削除される。 RIPv2 では可変長サブネットマスクに対応している。 欠点 30秒後とのレギュラーアップデートなので、経路情報の伝播には時間がかかる。また、ブロードキャストなので、ネットワークへの負荷がかかる。RIPv2 ではレギュラーアップデートはブロードキャストではなく、マルチキャスト (224.0.0.9) で送られるが、送信周期は 30 秒で同じ。 RIP におけるメトリック値の上限は 16 であり、その値が設定されると、使用できないルートであるという意味になる。結果として、RIP は 16 個以上のルータを経由する大規模なネットワークには適用できない。逆に、この制限のおかげで経路のループによる問題が起こらないようになっている。 経路はメトリック値だけで判断されるので、回線速度、品質が考慮されない。 OSPF (Open Shortest Path First) 特徴 RIP の課題を解決したプロトコル。 回線速度などを考慮しているので、WAN を含む中～大規模のネットワークに適用できる。 RIP よりも複雑で構築が難しい。 OSPF をサポートする機器は、RIP だけサポートしている機器に比べて高価。 仕組み サブネットに主従関係を持たせ、1 つのルータを代表ルータとする。そのサブネット内のルータ情報は代表ルータが集中管理して他のサブネットへ通知するため、通信量が RIP に比べて少ない。 サブネット内のルータの中で、プライオリティ値が一番高く設定されているものが代表ルータとなる。ルータのプライオリティ値は各インタフェースごとに設定できる。 RIP のように定期的に情報を送信（レギュラーアップデート）するのではなく、ルータ情報に変化が起きたときにただちに情報が伝えられる。ネットワークへの負荷が少なく、情報の更新が速い。 ルータの各ポートにコスト値が設定され、この値を元にメトリック値が計算され、最適な経路が決定される。コスト値は手動で設定することも自動で計算することもできる。 16 台以上のルータを越えるルーティングが可能。 可変長サブネットマスクに対応している。 BGP-4 プロバイダ向け。</description></item><item><title>NAT の種類のメモ（SNAT、DNAT、NAPT、IP マスカレード）</title><link>https://maku77.github.io/p/25gurcf/</link><pubDate>Wed, 07 May 2008 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/25gurcf/</guid><description>NAT (Network Address Translation) とは、パケット中の IP アドレスを書き換える技術のことをいいます。 送信元、送信先のどちらを書き換えるかで次のように区別することもあります。
SNAT (Source NAT) 送信元の IP アドレスを書き換える DNAT (Destination NAT) 送信先の IP アドレスを書き換える IP アドレスだけでなく、TCP や UDP のポート番号も同時に変換する機能を NAPT (Network Address Port Translation)、あるいは IP マスカレードといいます。 この機能は、ブロードバンドルータなどによく実装されています。
ネットワークのインタフェースを複数持っている端末で、NAT による設定を行うことで、柔軟なルーティングを行えるようになります。 例えば、Linux マシンに 2 枚の NIC（ネットワークカード）を挿して、iptables で NAT の設定を行えば、その Linux マシンをルータとして利用できるようになります。</description></item><item><title>ルーティングテーブルの管理</title><link>https://maku77.github.io/p/8yz2uga/</link><pubDate>Tue, 22 Apr 2008 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/8yz2uga/</guid><description>ルーティングテーブルを表示する Linux の場合 $ /sbin/route Windows の場合 C:\&amp;gt; route print ルーティングテーブルにエントリを追加する Linux の場合 $ route add -net &amp;lt;NetworkAddr&amp;gt; netmask &amp;lt;NetMask&amp;gt; gw &amp;lt;GatewayAddr&amp;gt; [Metric] [Interface] 実行例 $ route add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.100.254 metric 1 eth0 Windows の場合 C:\&amp;gt; route add &amp;lt;NetworkAddr&amp;gt; netmask &amp;lt;NetMask&amp;gt; gateway &amp;lt;GatewayAddr&amp;gt; ルーティングテーブルからエントリを削除する Linux の場合 $ route del -net 192.168.1.0 netmask 255.255.255.0 ネットワーク・トラブルの調査 (Windows) ルータに ping は通るが他のネットワークに ping が通らないケース route print コマンド（あるいは netstat -r）でルーティングテーブルを表示し、デフォルトゲートウェイのアドレスを確認します。 正しいルータのアドレスになっていなければ、NIC の設定で正しいアドレスを設定します。</description></item><item><title>テキストからシーケンス図を作成するツール (sdedit)</title><link>https://maku77.github.io/p/r3udg6c/</link><pubDate>Thu, 10 Jan 2008 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/r3udg6c/</guid><description>sdedit とは UML 図をグラフィカルに作成することのできるツールはたくさんありますが、シーケンス図のように処理の前後関係を頻繁に入れ替えたくなる図は、逆にグラフィカルなツールでの修正は面倒かもしれません。 Quick Sequence Diagram Editor (sdedit) は、テキストでシーケンスを定義し、画像ファイルとして出力することのできるツールです。
Quick Sequence Diagram Editor - SourceForge Quick Sequence Diagram Editor - GitHub このツール自体はグラフィカルな UI を提供しており、テキストエリアに専用のフォーマットでシーケンスを入力していくと、リアルタイムに図が更新されていきます。 他にも次のような特徴があります。
いろんな画像フォーマットで出力できる。ベクタ形式の EMF で出力して、PowerPoint などにきれいに貼り付けることも可能。 図中のコンポーネントをクリックすると、その定義位置へジャンプできる。 TAB キーで入力補間できる。 日本語も表示可能。 シーケンスの書き方 オブジェクトを定義する Object section と、メッセージのやりとりを定義する Message section を分けて記述していきます。 Object section と Message section は空白行で区切って定義します。
Object section の記述 シーケンス図内に登場させるオブジェクトは、Object section で次のように定義します。 行の先頭を # で始めるとコメント行になります。
# Object section a:ClassA b:ClassB c:ClassC Invisible object オブジェクト定義時にプレフィックスとして /（スラッシュ）を付けると、そのオブジェクトは Invisible object となり、Message section で他のオブジェクトから new されるまで図に表示されなくなります。 逆に、destroy メッセージによって図から削除することができます。 次のコードは、オブジェクト a が b を new し、最後に destroy することを示しています。</description></item><item><title>make を使いこなすためのメモ</title><link>https://maku77.github.io/p/3r6ds3r/</link><pubDate>Fri, 29 Jun 2007 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/3r6ds3r/</guid><description>make の種類あれこれ 一番よく使用されているのは GNU make ですが、いろいろな亜種があります。
System V make Stuart I. Feldman によって作成されたオリジナルの make です GNU make Linux の世界で一般的に使用されている make です Implemented by Richard Stallman and Roland McGrath. Development since Version 3.76 has been handled by Paul D. Smith. Microsoft 版 nmake Microsoft C コンパイラ ver. 6.0A に付属 Borland 版 make Borland Turbo C++ コンパイラ ver.2 に付属 参考: MAKE の達人 (1992)
Makefile に記述する rule のフォーマット Makefile には、下記のようなフォーマットで rule を記述していきます。
targets : prerequisites command .</description></item><item><title>VMware のネットワーク設定</title><link>https://maku77.github.io/p/vugpfvz/</link><pubDate>Thu, 22 Mar 2007 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/vugpfvz/</guid><description>VMware Player 1.0.3 で確認しています。
仮想ネットワーク (virtual network)／仮想スイッチ (virtual switch) VMware をインストールすると、最大 9 つの virtual network（VMnet0 ～ VMnet8）が利用できるようになります。 デフォルトの設定では、VMnet0、VMnet1、VMnet8 がそれぞれ次のような構成のネットワークとして設定されています。
VMnet0: bridged network（ブリッジ接続ネットワーク） VMnet1: host-only network（ホストオンリー接続ネットワーク） VMnet8: NAT network（NAT 接続ネットワーク） 例えば、デフォルトで VMnet0 は物理的な NIC と接続するための virtual bridge（仮想ブリッジ）として使えるようになっているので、virtual machine（ゲスト OS）の virtual network adapter（仮想ネットワークアダプタ）を VMnet0 に接続するように設定すれば、物理的な NIC が繋がっている外のネットワークに接続することができます。
[virtual machine] virtual network adapter ---&amp;gt; VMnet0 (bridge) ---&amp;gt; [physical NIC] ---&amp;gt; external network virtual network (VMnet\*) の数は上記のように 9 個までと制限されていますが、ひとつの virtual network に対して複数の virtual machine（正確には virtual network adapter）を接続することができるので、ほとんど問題にはなりません（Windows ホストでは接続数に制限なし、Linux ホストでは 32 個の virutal network adapter をひとつの virtual network に接続可能）。</description></item><item><title>プログラム内のコメントの書き方 (Javadoc ドキュメンテーションコメントの書き方）</title><link>https://maku77.github.io/p/fiw27s4/</link><pubDate>Mon, 12 Jul 2004 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/fiw27s4/</guid><description>はじめに（モチベーション） こんな話があります。あるソフトウェア企業が一人の技術者の採用を決めました。その決め手となった理由は、「公開しているオープンソースソフトウェアのドキュメントが素晴らしかったから」です。彼らは、作成されたドキュメントを見ただけで、その人には技術力がある、一緒に働いて欲しいと判断したのです。
ある国の言語を学ぶために読み書きの練習が必要であるのと同様に、コーディング技術をつけるには、多くの良質なコードを読み、多くのコードを書くことが必要です。設計ドキュメントを書くのも同じことです。日頃から分かりやすいドキュメントを書く鍛錬を怠らず、長年の経験を積んでいかなければ、良質なドキュメントを書く力は身に付きません。今日からドキュメンテーションコメントをバリバリ書いて、ドキュメンテーション力を付けていきましょう。
Let's Enjoy ドキュメンテーションコメント! ドキュメンテーションコメントとは？ API の使用方法を表すコメント（＝ドキュメンテーションコメント） ドキュメンテーションコメントは「APIの仕様」であり、主に API を使用する人のために記述するものです。そのため、通常は public あるいは protected なメソッドや、フィールドが記述の対象となります。ドキュメンテーションコメントを見ただけで、その API を正しく使えるようになっている必要があります。ある API を使おうと思った時に、そのメソッドの実装を見なければ呼び出し方が分からないようであれば、正しく説明ができていないということです。
Java の ドキュメンテーションコメントは /** */ という形式の Javadoc フォーマットで記述します。C# では ///、Python では &amp;quot;&amp;quot;&amp;quot; と、いろいろ書き方はありますが、何を書くべきかという本質的な部分はどの言語でも同じです。Javadoc フォーマットでコメントを記述しておくと、javadoc コマンドを使ってドキュメントファイルを生成できます（一般的に HTML 形式で出力します）。javadoc コマンドは、デフォルトで public/protected メソッドのみドキュメントを生成するようになっています。
API の実装方法を表すコメント（＝通常コメント） そのメソッドを「どのように実装しているのか」を示すコメントは、実装者のための通常コメントであり、ドキュメンテーションコメントとしては出力しなくてもよいものです。private メソッドとして実装される部分は、この種のコードに該当します。private メソッドを使用できる状況というのは、つまりは、そのクラスのコードを参照しながら作業しているということなので、ドキュメントとして出力する必要はないということです。これは、private なフィールドにコメントが必要ないということではないので注意してください。詳細実装に必要なコメントは private なフィールドに対しても記述しておくべきです。Java では、通常のコメントは // や /* */ を使って記述します（もちろん Javadoc 形式 /** */ でも記述可能です）。
コメントを記述するときは、API 実装者のためのコメント（実装方法）と、API 使用者のためのコメント（使用方法）のどちらを書いているのかを常に意識しましょう。
なぜドキュメンテーションコメントが必要なのか？ 一般公開する目的で作られたライブラリにドキュメントが必要なのは明らかです（中には、「コード読め」、「試しながら使え」、といったやる気なしライブラリもありますが）。一方で、内製のアプリケーションを作成するときにも、ドキュメンテーションコメントを記述すべき理由があります。
多人数での開発効率を上げるため 大規模なソフトウェアを開発する場合、多人数でコードを共有して修正していくことはよくあることです。他の人が作成した API を呼び出すこともありますし、その API を修正しなければならないこともあります。このとき、API 仕様が明確になっていないと、正しく API を呼び出すことはできませんし、既存のコードを正しく修正することもできません。その結果、全体のコード品質は低下し、メンテナンスコストは増大していきます。</description></item><item><title>型変換用メソッドは受け取り側クラスに作る</title><link>https://maku77.github.io/p/sxmuvwz/</link><pubDate>Mon, 04 Aug 2003 00:00:00 +0000</pubDate><guid>https://maku77.github.io/p/sxmuvwz/</guid><description>あるアプリケーションドメイン内のクラスにおいて、データ変換用のメソッドを用意する場合は、自分自身のデータを他のデータ型に変換するメソッドを作るのではなく、他のデータを自分自身の型に変換するメソッドを用意すると全体の構造がすっきりします。
public class A { public static A convertFrom(B b) { ... } // コンストラクタで他のデータ型から変換する方法もあり } 利点は、変換元のクラスに変換先クラスの知識を持たせないでよいことと、以下のように一貫した呼び方で、いろんなオブジェクトからの変換を行えることです。
A a = A.convertFrom(b); A a = A.convertFrom(c); A a = A.convertFrom(d); 次のように変換元のクラスにメソッドがたくさん増えるのはあまり格好良くないです。
B b = a.createB(); C c = a.createC(); D d = a.createD(); ただ、これは変換先の型への依存関係をどちらに持たせるかの問題なので、後者の方法しかとれない場合もあります。
変換メソッドのいい例は Java の Integer クラスなどです。Integer.valueOf() メソッドは、引数で受け取ったデータから、Integer オブジェクトを生成します（ちなみに、プリミティブな int 型が欲しいときは Integer.parseInt() の方を使います）。
Integer a = Integer.valueOf(100); Integer b = Integer.valueOf(&amp;#34;100&amp;#34;);</description></item></channel></rss>